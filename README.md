# Data Warehouse Project
## Project Description:
The purpose of this project was to build an ETL pipeline that would load data from S3 to staging tables and analytics tables on Amazon Redshift for easy analysis of user activity for the music streaming startup, Sparkify. The SQL queries were created first in the sql_queries.py file. These queries create all the requisite tables, drop tables if necessary, and contain queries for the insertions and copies for the star schema tables and staging tables respectively. Next I enclosed the necessary credentials to start a redshift cluster in the file dwh.cfg. I erased the contents of the dwh.cfg file for security purposes. Then came the actual creation of the tables by running the create_tables.py file in the terminal. Lastly I ran the etl.py file to prepare the data for analysis.
